# -*- coding: utf-8 -*-
"""module2.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11dsNewBQOc98XgTUaK7FVuSQmjWdozi2
"""

!pip install easyocr

!pip install pymupdf

!pip install langdetect

import re
from langdetect import detect, LangDetectException
from final_ocr_pipeline import extract_text



class TextProcessor:
    def __init__(self):
        pass

    # ---------- Cleaning ----------
    def clean_text(self, text):
        text = re.sub(r"[ \t]+", " ", text)
        text = re.sub(r"\n+", "\n", text)
        return text.strip()

    # ---------- Sentence Split ----------
    def split_sentences(self, text):
        return re.split(r'(?<=[.!?])\s+', text)

    # ---------- Chunking ----------
    def chunk_text(self, text, chunk_size=500):
        return [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]

    # ---------- Language Detection ----------
    def detect_language(self, text):
        try:
            return detect(text)
        except LangDetectException:
            return "en"

    # ---------- TTS Preparation ----------
    def prepare_text_for_tts(self, text):
        lang = self.detect_language(text)

        if lang == "ur":
            text = text.replace("۔", ".").replace("،", ",").replace("\n", " ")
        else:
            text = text.replace("\n", " ")
            lang = "en"

        return {
            "language": lang,
            "text": text.strip()
        }


if __name__ == "__main__":
    file_path = input("Enter PDF or Image path: ")

    raw_text = extract_text(file_path)

    processor = TextProcessor()
    cleaned = processor.clean_text(raw_text)

    print("\nCLEANED TEXT:\n", cleaned[:1000])
    print("\nLANGUAGE:", processor.detect_language(cleaned))